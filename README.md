# Projet_Prediction_des_Ventes
Projet de prédiction des ventes
# -*- coding: utf-8 -*-
"""Prevention_des_ventes_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bk5pEDy47f9qa6OaS67vS5cDv6g55WpC

# Machine Learning pour la prédiction des ventes

les premiers tests...



1. Data processing


2. Model building


3. Model training and testing


4. conclusion
"""

import pandas as pd
df=pd.read_csv("output.csv")

df.head()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

plt.scatter(df['Item_id'],df['Month_sales'])

max(df['Month_sales'])

"""On peut voir ici qu'on a besoin de savoir le nombre de vente de chaque produit par mois , donc on a besoin du nombre de vente et du mois pour chaque id, c'est à dire On peut rien faire avec un seul fichier month_sales0.csv

**On va  telecharger tout les fichiers month_sales et creer un grand fichier qui les groupe en un seul tableau**
"""

df_train=pd.read_csv("output.csv")

"""Maintenant On peut visualiser l'evolution des ventes 
chaque mois pour les produit 22154,2564,2555.
"""

list_items=[22154,2564,2555]
colors=['b','r','g']
i=0
o=0
for item in list_items:
  df_item=df_train.loc[(df_train["Item_id"]==item),["Item_id","Month_sales","month"]]
  plt.bar( df_item['month']+o ,df_item['Month_sales'],color=colors[i],width=0.2)
  i+=1
  o+=0.2

"""Maintenant on doit créer notre data pour l'entrainement du modèle, 
on prend: 

X:  mois et id de produit                               
Y: nombre de vente pour ce mois
"""

x=df_train.drop(columns=['Month_sales'])
y=df_train['Month_sales']
n_cols = x.shape[1]
x.head()

"""#Premier modèle

Maintenant on va diviser le dataframe en 80% pour le training et 20% pour le test.

Pour cela on va travailler avec le module sklearn
"""

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,shuffle=True)

a=len(df_train)
b=len(x_train)
ratio=b/a
print("la data de training fait "+str(ratio*100)+ "% de la data totale")

"""Maintenant on doit créer un reseau de neurone pour attaquer la data obtenue.
Pour cela ona besoin des modules keras et tensorflow-gpu( car il est plus rapide et optimisé)
"""

import tensorflow as tf
from tensorflow import keras

#we might need numpy too
import numpy as np
#pour voir la version du tensorflow utilisé j'ai installé la dernier version stable
print(tf.__version__)

"""Maintenant, comme début, on definit notre modèle:

---



couche d'entrée: 2 neurones (month et id_item)


---


couche cachée 1: 128 neurones/activation reLu


---


couche cachée 2: 128 neurones/activation reLu


---


couche de sortie:1  neurone (month_sales) / activation sigmoid


---
"""

from tensorflow.python.keras.layers import Dense
from tensorflow.python.keras import Sequential
from tensorflow.python.keras.callbacks import EarlyStopping

model1= Sequential([Dense(16,activation='relu',input_shape=(n_cols,)),
                   Dense(24,activation='relu'),
                   Dense(1)])

model1.compile(optimizer='adam',
              loss='mean_squared_error',
              metrics=['accuracy'])

early_stopping_monitor = EarlyStopping(patience=3)
hist = model1.fit(x_train, y_train,
          batch_size=32, epochs=30,validation_split=0.2,callbacks=[early_stopping_monitor])

x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,shuffle=True)
model1.evaluate(x_test, y_test)

"""#Prédiction premier modèle pour le produit 2552"""

produit=2552
x=np.array([[produit,i] for i in range(40)])
mois=np.array([x[i][1] for i in range(len(x))])
Vente_reel=df_train.loc[(df_train["Item_id"]==produit),["month","Month_sales"]]
Vente_reel=Vente_reel.sort_values('month')
Vente_reel.set_index('month')
q=model1.predict(x)
plt.plot(mois,q,label='Vente prévu')
plt.plot(Vente_reel['month'],Vente_reel['Month_sales'],label='Vente réel')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.title("Prediction du premier modéle non amélioreé")



"""#Deuxieme modèle

Alors on trouve pour un premier temps que ce modèle a 24% de précision. On doit soit optimiser la data en réordonnant la base de données. On peut aussi travailler sur le modèle , en ajoutant par exemple d'autres couches de neurones et en augmentant le nombre de neurones.
"""

model2= Sequential([Dense(8,activation='relu',input_shape=(n_cols,)),
                   Dense(16,activation='relu'),
                   Dense(32,activation='relu'),
                   Dense(16,activation='relu'),
                    Dense(8,activation='relu'),
                   Dense(1)])

model2.compile(optimizer='adam',
              loss='mean_squared_error',
              metrics=['accuracy'])

hist = model2.fit(x_train, y_train, batch_size=128, epochs=10,validation_data=(x_test,y_test),callbacks=[early_stopping_monitor])

model2.evaluate(x_test,y_test)

"""la précision est de 24%
 même si on a augmenté la capacité du modèle. C'est pourquoi nous pensons que le problème provient de la lecture des données. En effet, les données d'entrée ne conviennent pas à notre modèle d'apprentissage.
"""

produit=2552
x=np.array([[produit,i] for i in range(40)])
mois=np.array([x[i][1] for i in range(len(x))])
Vente_reel=df_train.loc[(df_train["Item_id"]==produit),["month","Month_sales"]]
Vente_reel=Vente_reel.sort_values('month')
Vente_reel.set_index('month')
q=model2.predict(x)
plt.plot(mois,q,label='Vente prévu')
plt.plot(Vente_reel['month'],Vente_reel['Month_sales'],label='Vente réel')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.title("Prédiction du Premier modéle amélioré")

"""# Changement des données

Nous allons reprendre le tableau training.csv pour avoir des données plus comprehensibles pour le modèle afin d'augmenter la précision.
"""

import pandas as pd
df=pd.read_csv("output.csv")

df.sort_values(by=['Month_sales'])

df.plot.line(x='month',y='Month_sales')

"""#Réorganisation de la base de données 

Maintenant, nous allons essayer une nouvelle approche, la dernière fois nous avions les mois sous formes d'entiers allant de 0 à 33. (0==>Janvier 2013, 33===>Octobere 2015)

Normalement, même pour un cerveau humain 33 ne contient pas assez d'informations pour savoir quel mois et quel années, il faut faire un calcul relatif à la date 0 (janvier 2013).

De plus, je crois que c'est mieux d'avoir les ventes pendant chaque mois pour tout les produits plutôt que pour chaque produit.

Finalement, nous pourrons faire la meme chose pour un produit defini, c'est-à-dire créer un modèle pour chaque produit si on cherche à prédire les ventes d'un produit particulier.

Dans le prochain test, nous allons prendre ces remarques en compte, et nous allons l'essayer sur ces 2 modèles:

*   Un modele de Deep learning simple sequentiel
*   un model Long-short Term Memory  (LSTM)

> **Preprocessing**
"""

df_sales= pd.read_csv("output.csv")
df_sales.dropna()
df_sales.sort_values(by=['Month_sales']) #il faut enlever les valeurs négatives

df_sales=df_sales[df_sales['Month_sales']>0]
df_sales.sort_values(by=['Month_sales']) #voila, il reste de grouper les ventes de chaque mois.

df_sales_monthly= df_sales.groupby('month').Month_sales.sum().reset_index()
df_sales_monthly.head()

"""Nous allons visualiser l'evolution des ventes"""

df_sales_monthly.plot(x='month') #il faut reconvertir les entiers en date

"""Nous observons qu'il y a des tendances et des pics qui se répètent. Nous pensons que ce modèle sera utilisable."""

df_sales_monthly['date']=pd.date_range(start='2013-01-01',periods=34 ,freq='M')
df_sales_monthly=df_sales_monthly.drop(columns='month')
df_sales_monthly.head()

df_sales_monthly=df_sales_monthly.rename(columns={'Month_sales':'sales'})

df_sales_monthly.plot(x='date') #nickel on peut  voir maintenant les dates et l'evolution des ventes

"""Maintenant nous avons quelque chose de compréhensible mais il faut quand même extraire les caractéristiques des données.

Dans ce cas, il est pertinent d'extraire la différence entre 2 mois de ventes. La courbe des ventes contient une pente ou tendance négative. Nous avons besoin de quelque chose de périodique pour avoir plus de precision.

Le modèle n'est pas performant en prenant en compte les tendances

Avant de pouvoir utiliser le machine learning, les problèmes de prévision de séries chronologiques doivent être recadrés comme des problèmes d'apprentissage supervisé. Il faut passer d'une séquence à des paires de séquences d'entrée et de sortie.
"""

df_diff=df_sales_monthly.copy()
df_diff['prev_sales']=df_diff['sales'].shift(1)
df_diff.dropna()

df_diff['delta']=df_diff['sales']-df_diff['prev_sales']

df_diff=df_diff.dropna()
df_diff.head()

df_diff.plot(x='date')

"""Le but maintenant est de prédire plutôt la difference, ce qui va nous permettre d'obtenir la valeur des ventes des prochains mois.

La courbe a une tendance périodique. Il sera plus facile de prédire les résultats pour les prochains mois.

Nous pouvons voir qu'il y a le même pic au niveau du mois décembre.
Cela sera utile pour créer la prédiction des ventes des prochains mois en utilisant les valeurs des derniers mois. Nous allons prendre une période sur 12 mois.

Cela va nous permettre de créer une base de données supervisée.
"""

df_supervised=df_diff.drop(columns='prev_sales')

for i in range(1,13):
  df_supervised['p'+str(i)]=df_diff['delta'].shift(i)

df_supervised=df_supervised.dropna().reset_index(drop=True)

df_supervised.head()

"""IL reste maintenant à tester ces données avec un modèle de régression linéaire.
On va utiliser p1 (la vente de tous les produits du mois précédent)  pour comprendre la variation de delta de facon numérique.
"""

import statsmodels.formula.api as smf
# defenir le modele avec une regression linaire
model = smf.ols(formula='delta ~ p1', data=df_supervised)
#appliquer la regression
model_fit = model.fit()
# calculer le coefficient de détermination,voir: https://fr.wikipedia.org/wiki/Coefficient_de_d%C3%A9termination pour plus d'info
regression_adj_rsq = model_fit.rsquared_adj
print(regression_adj_rsq)

"""La valeur n'est pas bonne pour une seule période. Nous allons maintenant l'utiliser avec les 12 mois précédents. Nous avons:"""

import statsmodels.formula.api as smf
# defenir le modele avec une regression linaire
model = smf.ols(formula='delta ~ p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 + p10 + p11 + p12', data=df_supervised)
#appliquer la regression
model_fit = model.fit()
# calculer le coefficient de détermination,voir: https://fr.wikipedia.org/wiki/Coefficient_de_d%C3%A9termination pour plus d'info
regression_adj_rsq = model_fit.rsquared_adj
print(regression_adj_rsq)

"""Nous remarquons qu'il y a une corrélation entre les 12 derniers mois et delta de 83%. Nous pouvons faire mieux en ajoutant 3 ou 4 mois."""

df_supervised=df_diff.drop(columns='prev_sales')

for i in range(1,17):
  df_supervised['p'+str(i)]=df_diff['delta'].shift(i)

df_supervised=df_supervised.dropna().reset_index(drop=True)

df_supervised.head()

import statsmodels.formula.api as smf
# defenir le modele avec une regression linaire
model = smf.ols(formula='delta ~ p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 + p10 + p11 + p12 + p13  ', data=df_supervised)
#appliquer la regression
model_fit = model.fit()
# calculer le coefficient de détermination,voir: https://fr.wikipedia.org/wiki/Coefficient_de_d%C3%A9termination pour plus d'info
regression_adj_rsq = model_fit.rsquared_adj
print(regression_adj_rsq)

"""Nous avons trouvé que 13 mois donne le meilleur resultat : 89.75% alors que 15 mois donne une correlation de 69%
, ce qui confirme notre premier visualisation : la courbe de delta se répète à peu près tous les 13 mois. Nous allons exploiter cette information pour notre modèle de Machine Learning.

En outre :  


*   Entrée: p1,...,p13 
*   Sortie: delta
"""

df_supervised=df_diff.drop(columns='prev_sales')

for i in range(1,14):
  df_supervised['p'+str(i)]=df_diff['delta'].shift(i)

df_supervised=df_supervised.dropna().reset_index(drop=True)

df_supervised.head()

"""Les données sont maintenant ordonnées, il reste à contruire une fonction réversible qui permet de mettre les valeurs d'entrée entre -1  et 1 pour qu'elles soient utilisables pour le modèle d'apprentissage auto.

Il existe un module qui s'appelle MinMaxscale

On prend les dernier 6 mois pour le test
"""

from sklearn.preprocessing import MinMaxScaler
df_model = df_supervised.drop(['sales','date'],axis=1)

nbr_mois=6

train_set, test_set = df_model[0:-nbr_mois].values, df_model[-nbr_mois:].values

#utilisation de MinMAxScaler pour le model
scaler = MinMaxScaler(feature_range=(-1, 1))
scaler = scaler.fit(train_set)
# reshape training set
train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])
train_set_scaled = scaler.transform(train_set) #train_set transformed to -1, 1
# reshape test set
test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])
test_set_scaled = scaler.transform(test_set) #test_set transformed to -1, 1

"""Maintenant on rentre dans les entrées du modèle, il faut simplement traiter les données avant créer le modèle."""

X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]
X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])

X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]
X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])

"""Le modèle utilise p1 , p2 ...., p13 pour trouver delta

Le modèle contient:

une entrée :  un tenseur de format [1,1,13]


------------------------------------
- Un reseau LSTM voir: https://en.wikipedia.org/wiki/Long_short-term_memory


------------------------

- Un neurone de sortie (un vecteur) : la valeur delta à predire.
"""

import keras
from keras.layers import Dense
from keras.models import Sequential
from keras.optimizers import Adam 
from keras.callbacks import EarlyStopping
from keras.utils import np_utils
from keras.layers import LSTM
from sklearn.model_selection import KFold, cross_val_score, train_test_split

model = Sequential()
model.add(LSTM(24, activation='softmax', recurrent_activation='sigmoid' ,batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))
model.add(Dense(1))
model.compile(loss='mean_absolute_percentage_error', optimizer='adam')
model.fit(X_train, y_train, epochs=200, batch_size=1, verbose=1, shuffle=False)

y_pred=model.predict(X_test,batch_size=1)
print(y_pred)

print(y_test)

"""Les valeurs se rapprochent quand même mais il est pertinent de voir cela dans un graph."""

import numpy as np

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

x=np.array([1,2,3,4,5,6])
y1=y_pred
y2=y_test
plt.plot(x,y1,y2)

"""il y a une difference mais c'est parce que nous sommes sur un domaine de [-1,1]. Cela peut disparaitre dans le domaine original.


Pour cela, l'étape suivante est de faire l'operation inverse
"""

#reshape y_pred
y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])
#rebuild test set for inverse transform
pred_test_set = []
for index in range(0,len(y_pred)):
    pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))
#reshape pred_test_set
pred_test_set = np.array(pred_test_set)
pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])
#inverse transform
pred_test_set_inverted = scaler.inverse_transform(pred_test_set)

df_sales_monthly.head()

df_sales_monthly['date'] = pd.to_datetime(df_sales_monthly['date'])

#create dataframe that shows the predicted sales
result_list = []
sales_dates = list(df_sales_monthly[-(len(pred_test_set_inverted)+1):].date)
act_sales = list(df_sales_monthly[-(len(pred_test_set_inverted)+1):].sales)
print(act_sales)
for index in range(0,len(pred_test_set_inverted)):
    result_dict = {}
    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])
    result_dict['date'] = sales_dates[index+1]
    result_list.append(result_dict)
df_result = pd.DataFrame(result_list)
#for multistep prediction, replace act_sales with the predicted sales

df_result

df_result.plot(x='date')

import plotly.offline as pyoff
import plotly.graph_objs as go

df_sales_pred = pd.merge(df_sales_monthly,df_result,on='date',how='left')

#plot actual and predicted
plot_data = [
    go.Scatter(
        x=df_sales_pred['date'],
        y=df_sales_pred['sales'],
        name='actual'
    ),
        go.Scatter(
        x=df_sales_pred['date'],
        y=df_sales_pred['pred_value'],
        name='predicted'
    )
    
]
plot_layout = go.Layout(
        title='Sales Prediction'
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
pyoff.iplot(fig)

"""Notre prédiction a la même tendance que les données réelles. Il n y a pas une grande différence entre ce qu'on a et le modèle de prédiction."""

df_supervised.tail()

"""Nous avons utilisé les 13 mois précédents pour trouver le prochain delta.


Par conséquent, si on veut trouver les ventes de novembre 2016, il suffirait de donner au modèle les informations des 13 mois précédents.
"""

def predire(nbr_mois_predire):

    t=np.array(df_supervised['delta'][-14:])[::-1]
    for i in range(nbr_mois_predire):
        x= np.array([t])
        x=scaler.transform(x)
        x=x[:, :-1].reshape(1,1,13)
        y=model.predict(x)
        y = y.reshape(y.shape[0], 1, y.shape[1])
        pred = []
        pred.append(np.concatenate((y,x),axis=2))
        pred = np.array(pred)
        pred = pred.reshape(pred.shape[0], pred.shape[3])
        #inverse transform"""
        y_inverted = scaler.inverse_transform(pred)
        New_delta=y_inverted[0][0]
        t=np.append(New_delta,t)
        t=t[0:14]

    last_sale=list(df_sales_pred['pred_value'][-1:])
    four_months_diff= t[0:nbr_mois_predire]
    next_sales=last_sale
    for i in range(nbr_mois_predire):
      last=next_sales[i]
      next_sales.append(four_months_diff[3-i]+last)
    df_pred_four=pd.DataFrame({"pred_sales":next_sales})
    df_pred_four['date']=pd.date_range(start='2015-10-01',periods=len(next_sales),freq='M')
    df_sales_future = pd.merge(df_sales_monthly,df_pred_four,on='date',how='outer')
    plot_data = [
    go.Scatter(
    x=df_sales_future['date'],
    y=df_sales_future['sales'],
    name='actual'
        ),
    go.Scatter(
    x=df_sales_future['date'],
    y=df_sales_future['pred_sales'],
    name='predicted'
      )

    ]
    plot_layout = go.Layout(
    title='Sales Prediction'
        )
    fig = go.Figure(data=plot_data, layout=plot_layout)
    pyoff.iplot(fig)

  #y_november=model.predict([[X_november]])

predire(4)

predire(18)

"""Le modèle peut techniquement prédire jusqu'au 18 mois suivants mais d'après la visualisation, on peut facilement dire qu'il n'est pas fait pour une prédiction à long terme (1-2 ans).

A part cela, nous pouvons voir qu'il a bien détecté la tendance négative et il l'a linearisé pour donner la prédictions des prochains mois

En outre, cette monotonie ou cette fonctions lineaire vient du fait qu'il y a vraiment une tendance négative mais aussi du fait que nous avons pas pris en compte les saisons, les vacances, les fêtes...

Cela peut ajouter plusieurs variables à notre modèle, ce qui rendrait la prédiction à long terme plus précise. Toutefois, si on veut une prédiction pour les 2-3 prochains mois, ce modèle suffira.
"""
